{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "Workflow\n",
    "\n",
    "1. x - Upload the dataset from MelanomaDetection.zip to the GPU server. Note that strictly speaking, you do not have to use a GPU for completing this milestone. This stepâ€™s objective is to make sure that you know how to get your dataset onto wherever your GPU is, and access it from there.\n",
    "\n",
    "2. Write a custom class for the unlabeled images that inherits `torch.utils.data.Dataset` and overrides the following methods:\n",
    "   * `__init__(self, dir_path, transform=None)`: the constructor should take in a path to the directory containing images and an optional transform argument for image pre-processing and augmentation.\n",
    "   * `__len__(self)`: should return the number of images in the dataset.\n",
    "   * `__getitem__(self, i)`: should return the ith image in the set.\n",
    "\n",
    "\n",
    "3. Write a custom class for the labeled images that inherits `torch.utils.data.Dataset` and overrides the following methods:\n",
    "   * `__init__(self, dir_path, transform=None)`: the constructor should take in a path to the directory containing images and an optional transform argument for image pre-processing and augmentation\n",
    "   * `__len__(self)`: should return the number of images in the dataset\n",
    "   * `__getitem__(self, i)`: should return the ith image in the set as well as its label\n",
    "\n",
    "\n",
    "4. Instantiate both classes and create two torch.utils.data.DataLoader objects (for the unlabeled and labeled datasets respectively). Use them to print out one batch of data each.\n",
    "\n",
    "5. After looking at the images, what transformations do you propose to use for the pre-processing and the data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "* https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/\n",
    "* Manning Chapters - PyTorch Book\n",
    "  - Augmentation - https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-12\n",
    "  - DataLoading - https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://liveproject-resources.s3.amazonaws.com/other/MelanomaDetection.zip'\n",
    "pth = './data/MelanomaDetection.zip'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "from skimage import io\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "if not os.path.exists(pth):\n",
    "    urllib.request.urlretrieve(url, pth)\n",
    "    with ZipFile(pth, 'r') as zipObj:\n",
    "        zipObj.extractall('./data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Unlabeled Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LEFT OFF HERE - more to write. \n",
    "\n",
    "class MILabeled(Dataset):\n",
    "    def __init__(self, dir_path, transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        files = os.listdir(dir_path)\n",
    "        self.labeled_images = filter(None, [self._parse_files(f) for f in files])     \n",
    "        \n",
    "  \n",
    "    \n",
    "    def __get_item__(self, i):\n",
    "        pass\n",
    "    \n",
    "    def _parse_files(self,pth):\n",
    "        \n",
    "        fn = os.path.basename(pth)\n",
    "        m = re.search(r'_(\\d)\\.', fn)\n",
    "        if m:\n",
    "            label = int(m.group(1))\n",
    "            file  = io.read(pth)\n",
    "            return (label, file)\n",
    "            \n",
    "            \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def __len__(self,i):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Labeled Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
