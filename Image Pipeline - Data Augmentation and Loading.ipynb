{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "Workflow\n",
    "\n",
    "1. x - Upload the dataset from MelanomaDetection.zip to the GPU server. Note that strictly speaking, you do not have to use a GPU for completing this milestone. This stepâ€™s objective is to make sure that you know how to get your dataset onto wherever your GPU is, and access it from there.\n",
    "\n",
    "2. Write a custom class for the unlabeled images that inherits `torch.utils.data.Dataset` and overrides the following methods:\n",
    "   * `__init__(self, dir_path, transform=None)`: the constructor should take in a path to the directory containing images and an optional transform argument for image pre-processing and augmentation.\n",
    "   * `__len__(self)`: should return the number of images in the dataset.\n",
    "   * `__getitem__(self, i)`: should return the ith image in the set.\n",
    "\n",
    "\n",
    "3. Write a custom class for the labeled images that inherits `torch.utils.data.Dataset` and overrides the following methods:\n",
    "   * `__init__(self, dir_path, transform=None)`: the constructor should take in a path to the directory containing images and an optional transform argument for image pre-processing and augmentation\n",
    "   * `__len__(self)`: should return the number of images in the dataset\n",
    "   * `__getitem__(self, i)`: should return the ith image in the set as well as its label\n",
    "\n",
    "\n",
    "4. Instantiate both classes and create two torch.utils.data.DataLoader objects (for the unlabeled and labeled datasets respectively). Use them to print out one batch of data each.\n",
    "\n",
    "5. After looking at the images, what transformations do you propose to use for the pre-processing and the data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "* https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/\n",
    "* Manning Chapters - PyTorch Book\n",
    "  - Augmentation - https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-12\n",
    "  - DataLoading - https://livebook.manning.com/book/deep-learning-with-pytorch/chapter-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://liveproject-resources.s3.amazonaws.com/other/MelanomaDetection.zip'\n",
    "pth = './data/MelanomaDetection.zip'\n",
    "unp = './data/MelanomaDetection'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "from skimage import io\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "if not os.path.exists(pth):\n",
    "    urllib.request.urlretrieve(url, pth)\n",
    "    with ZipFile(pth, 'r') as zipObj:\n",
    "        zipObj.extractall('./data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Unlabeled Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, item):\n",
    "\n",
    "        if type(item) is tuple:\n",
    "            img, label = item\n",
    "        else:\n",
    "            img = item\n",
    "            \n",
    "        img = torch.from_numpy(img.transpose(2,0,1))\n",
    "        \n",
    "        return (img, label) if type(item) is tuple else img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLUnlabeled(Dataset):\n",
    "    \n",
    "    def __init__(self, dir_path, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        files = os.listdir(dir_path)\n",
    "        self.images = [ io.imread(dir_path+'/'+f) for f in files if re.search('.jpg$', f)]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        ia = self.images[i]\n",
    "        \n",
    "        it = self.transform(ia) if self.transform else ia\n",
    "\n",
    "        \n",
    "        return it\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an Labeled Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILabeled(Dataset):\n",
    "    def __init__(self, dir_path, transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.dir_path  = dir_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        files = os.listdir(dir_path)\n",
    "        self.labeled_images = list(filter(None, [self._parse_files(f) for f in files]))    \n",
    "        \n",
    "  \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        (label, ia) = self.label_images[i]\n",
    "        \n",
    "        it = self.transform(ia) if self.transform else ia\n",
    "        \n",
    "        return (label, it)\n",
    "    \n",
    "    def _parse_files(self, fn):\n",
    "        \n",
    "        pth = self.dir_path + '/' + fn\n",
    "        #fn  = os.path.basename(pth)\n",
    "        m   = re.search(r'_(\\d)\\.', fn)\n",
    "        if m:\n",
    "            label = int(m.group(1))\n",
    "            f_arr  = io.imread(pth)\n",
    "            return (label, f_arr)\n",
    "            \n",
    "            \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def __len__(self,i):\n",
    "        len(self.labeled_images)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=10\n",
    "unlabeled_ds = MLUnlabeled(unp+'/unlabeled', ToTensor())\n",
    "labeled_ds = MILabeled(unp + '/labeled', ToTensor())\n",
    "\n",
    "u_dl = DataLoader(unlabeled_ds, batch_size=bs)\n",
    "l_dl = DataLoader(labeled_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print one batch each\n",
    "\n",
    "u_batch_list = list(u_dl)\n",
    "b1 = u_batch_list[0]\n",
    "\n",
    "### Left off here. Print 10 images from the batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_ds = MLUnlabeled(unp+'/unlabeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[234, 158, 171],\n",
       "        [232, 156, 168],\n",
       "        [229, 151, 164],\n",
       "        ...,\n",
       "        [246, 161, 166],\n",
       "        [244, 159, 164],\n",
       "        [241, 156, 161]],\n",
       "\n",
       "       [[233, 157, 169],\n",
       "        [226, 150, 162],\n",
       "        [227, 150, 160],\n",
       "        ...,\n",
       "        [243, 158, 163],\n",
       "        [240, 155, 160],\n",
       "        [238, 153, 158]],\n",
       "\n",
       "       [[230, 154, 164],\n",
       "        [222, 146, 156],\n",
       "        [226, 149, 157],\n",
       "        ...,\n",
       "        [238, 156, 160],\n",
       "        [236, 154, 158],\n",
       "        [234, 152, 156]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[223, 141, 143],\n",
       "        [227, 145, 147],\n",
       "        [229, 147, 149],\n",
       "        ...,\n",
       "        [227, 150, 144],\n",
       "        [224, 147, 141],\n",
       "        [221, 142, 137]],\n",
       "\n",
       "       [[227, 142, 145],\n",
       "        [230, 148, 150],\n",
       "        [231, 149, 151],\n",
       "        ...,\n",
       "        [228, 151, 145],\n",
       "        [226, 149, 143],\n",
       "        [225, 146, 141]],\n",
       "\n",
       "       [[228, 143, 146],\n",
       "        [231, 149, 151],\n",
       "        [233, 151, 153],\n",
       "        ...,\n",
       "        [228, 151, 145],\n",
       "        [228, 151, 145],\n",
       "        [228, 149, 144]]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = MILabeled(unp + '/labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, Array([[[190, 160, 158],\n",
       "         [189, 159, 157],\n",
       "         [189, 159, 157],\n",
       "         ...,\n",
       "         [187, 156, 164],\n",
       "         [185, 153, 164],\n",
       "         [184, 152, 163]],\n",
       " \n",
       "        [[187, 159, 158],\n",
       "         [187, 159, 158],\n",
       "         [188, 160, 159],\n",
       "         ...,\n",
       "         [187, 158, 163],\n",
       "         [187, 156, 162],\n",
       "         [185, 154, 160]],\n",
       " \n",
       "        [[183, 157, 158],\n",
       "         [184, 158, 159],\n",
       "         [186, 160, 161],\n",
       "         ...,\n",
       "         [189, 161, 160],\n",
       "         [188, 160, 159],\n",
       "         [187, 159, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[202, 169, 162],\n",
       "         [202, 171, 166],\n",
       "         [203, 172, 169],\n",
       "         ...,\n",
       "         [194, 164, 176],\n",
       "         [192, 164, 178],\n",
       "         [189, 161, 176]],\n",
       " \n",
       "        [[208, 171, 163],\n",
       "         [206, 171, 165],\n",
       "         [205, 172, 165],\n",
       "         ...,\n",
       "         [191, 165, 178],\n",
       "         [189, 165, 179],\n",
       "         [184, 160, 176]],\n",
       " \n",
       "        [[211, 173, 164],\n",
       "         [209, 172, 164],\n",
       "         [206, 171, 165],\n",
       "         ...,\n",
       "         [192, 168, 182],\n",
       "         [190, 167, 183],\n",
       "         [184, 161, 177]]], dtype=uint8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
