{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-test-env.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkytbjjHtdYG",
        "colab_type": "text"
      },
      "source": [
        "The Goal of this notebook is simply to ensure that environment is setup correctly.\n",
        "\n",
        "**Resources**\n",
        "\n",
        "* [MNIST (Medium Article)](https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627)\n",
        "* [Official Pytorch MNIST](https://github.com/pytorch/examples/tree/master/mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYFlY0CftVv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NPuV7SuDQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=16\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # need to check why this is done. \n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1, shuffle=False, batch_size=BATCH_SIZE)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, shuffle=False, batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL8aISPTu9XY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ead0077-3789-4684-dce7-c96401e95537"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7faae1ec21d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCYx02TyvuJD",
        "colab_type": "text"
      },
      "source": [
        "**Show Some Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Rr_VlGvwo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ifY2lYvyGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4dcedb32-53d9-4282-9ed9-9d6391f52a8f"
      },
      "source": [
        "def imshow(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "## get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "## show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkIHvDL6wDmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ddc8a690-a51c-4501-9522-9b12bd4bee3d"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    print(\"Image batch dimensions:\", images.shape)\n",
        "    print(\"Image label dimensions:\", labels.shape)\n",
        "    break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image batch dimensions: torch.Size([16, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}